dataset_config:
  dataset_split:
    train: [
      "8bit_AS4_CNT_S1_P1_L2_2560_1750_2160",
      "8bit_AS4_CNT_S1_P1_L3_2560_1750_2160",
      "8bit_AS4_CNT_S1_P1_L4_2560_1750_2160",
      "8bit_AS4_CNT_S1_P1_L5_2560_1750_2160",
      "8bit_AS4_CNT_S1_P1_L6_2560_1750_2160",
      "8bit_AS4_CNT_S2_P1_L5_2560_1800_2160",
      "8bit_AS4_S1_P1_L0_2560_1800_2160",
      "8bit_AS4_S1_P1_L1_2560_1800_2160",
      "8bit_AS4_S1_P1_L2_2560_1800_2160",
      "8bit_AS4_S1_P1_L3_2560_1800_2160",
      "8bit_AS4_S1_P1_L4_2560_1800_2160",
      "8bit_AS4_S1_P1_L5_2540_1720_2160",
      "8bit_AS4_S1_P1_L6_2560_1800_2160",
      "THIN_REF_S2_P1_L0_2508_1551_2159",
      "THIN_REF_S2_P1_L1_2434_1547_2159",
      "THIN_REF_S2_P1_L4_2433_1533_2159"
    ]
    validation: [
      "8bit_AS4_CNT_S2_P1_L0_2560_1800_2160",
      "8bit_AS4_CNT_S2_P1_L4_2560_1800_2160",
      "8bit_AS4_CNT_S2_P1_L6_2560_1800_2160",
      "THIN_REF_S2_P1_L2_2484_1524_2159",
      "THIN_REF_S2_P1_L3_2496_1563_2159",
    ]
    test: [
      "THIN_CNT_S2_P1_L0_2349_1578_2159",
      "THIN_CNT_S2_P1_L2_2293_1581_2159",
      "THIN_CNT_S2_P1_L3_2292_1566_2159",
      "THIN_CNT_S2_P1_L4_2334_1578_2159",
      "THIN_CNT_S2_P1_L5_2316_1542_2159",
      "8bit_AS4_S2_P1_L0_2560_1750_2160",
      "8bit_AS4_S2_P1_L4_2560_1750_2160",
      "8bit_AS4_S2_P1_L5_2560_1750_2160",
      "8bit_AS4_S2_P1_L6_2560_1750_2160"
    ]
  stack_downsampling:
    type: 'None' # 'None', 'random', 'linear', 'from_start', 'from_end'
#    frac: 1.0
#    number_of_images: 100
    num_skip_beg_slices: 5 # trims n slices off of beginning of stack with N total slices. Slice n+1 becomes new Slice 1
    num_skip_end_slices: 5 # trims m slices off of end of stack with N total slices. Slice N-(m+1) becomes new last slice
  target_size: [512, 512]  # width, height
  image_cropping:
    type: 'random' # 'None' (downscale img to target), 'linear' (def # crops), 'random' (def # crops), 'all' (all crops)
    num_per_image: 5 # if 'linear' (translation) or 'random' selected, then is num of crops (of target size) per image
  class_annotation_mapping:
    class_0_annotation_GVs: [100]  # '0-degree_damage'
    class_1_annotation_GVs: [175]  # '45-degree_damage'
    class_2_annotation_GVs: [250]  # '90-degree_damage'