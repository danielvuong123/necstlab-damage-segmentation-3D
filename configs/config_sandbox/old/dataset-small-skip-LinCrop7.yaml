dataset_config:
  dataset_split:
    train: [
      "THIN_REF_S2_P1_L3_2496_1563_2159",
    ]
    validation: [
      "THIN_CNT_S2_P1_L4_2334_1578_2159",
    ]
    test: [
      "8bit_AS4_S2_P1_L6_2560_1750_2160",
    ]
  stack_downsampling:
    type: 'None' # 'None', 'random', 'linear', 'from_start', 'from_end'
#    frac: 1.0
#    number_of_images: 100
    num_skip_beg_slices: 5 # trims n slices off of beginning of stack with N total slices. Slice n+1 becomes new Slice 1
    num_skip_end_slices: 5 # trims m slices off of end of stack with N total slices. Slice N-(m+1) becomes new last slice
  target_size: [512, 512]  # width, height
  image_cropping:
    type: 'linear' # 'None' (downscale img to target), 'linear' (def # crops), 'random' (def # crops), 'all' (all crops)
    num_per_image: 7 # if 'linear' (translation) or 'random' selected, then is num of crops (of target size) per image
  class_annotation_mapping:
    class_0_annotation_GVs: [100, 175, 250]  # '0-degree_damage', '45-degree_damage', '90-degree_damage'