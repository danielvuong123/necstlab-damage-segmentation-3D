dataset_config:
  dataset_split:
    train: [
      "RAK_OHC_100CDRY_Bat2Base2_BE80_L1_3065_2216_5440",
      "RAK_OHC_100CDRY_Bat2Base2_BE80_L4_3113_2245_5438",
    ]
    validation: [
      "RAK_OHC_100CDRY_Bat2Nano2_BE86_L1_3066_2214_5441",
    ]
    test: [
      "RAK_OHC_100CDRY_Bat2Nano2_BE86_L4_3102_2233_5425",
    ]
  stack_downsampling:
    type: 'None' # 'None', 'random', 'linear', 'from_start', 'from_end'
#    frac: 1.0
#    number_of_images: 100
    num_skip_beg_slices: 100 # trims n slices off of beginning of stack with N total slices. Slice n+1 becomes new Slice 1
    num_skip_end_slices: 100 # trims m slices off of end of stack with N total slices. Slice N-(m+1) becomes new last slice
  target_size: [512, 512]  # width, height
  image_cropping:
    type: 'random' # 'None' (downscale img to target), 'linear' (def # crops), 'random' (def # crops), 'all' (all crops)
    num_per_image: 10 # if 'linear' (translation) or 'random' selected, then is num of crops (of target size) per image
  class_annotation_mapping:
    class_0_annotation_GVs: [100, 250]  # '0-degree_damage', '90-degree_damage'
    class_1_annotation_GVs: [175]  # '45-degree_damage'